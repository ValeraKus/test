Using GATK jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar
Running:
    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1024M -jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar MarkDuplicatesSpark --input ../interim/CPCT12345678R_HJJLGCCXX_S1_L001.bam --tmp-dir /var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmp4u3jifbf --output ../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam --metrics-file ../interim/CPCT12345678R_HJJLGCCXX_S1_L001.metrics.txt --spark-master local[1]
22:34:43.782 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib
22:34:44.331 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
22:34:44.332 INFO  MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0
22:34:44.332 INFO  MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/
22:34:44.332 INFO  MarkDuplicatesSpark - Executing as vtimonin@SV-66M-004 on Mac OS X v10.16 x86_64
22:34:44.333 INFO  MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12
22:34:44.333 INFO  MarkDuplicatesSpark - Start Date/Time: December 26, 2022 10:34:43 PM CET
22:34:44.333 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
22:34:44.333 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
22:34:44.334 INFO  MarkDuplicatesSpark - HTSJDK Version: 3.0.1
22:34:44.334 INFO  MarkDuplicatesSpark - Picard Version: 2.27.5
22:34:44.334 INFO  MarkDuplicatesSpark - Built for Spark Version: 2.4.5
22:34:44.334 INFO  MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2
22:34:44.334 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false
22:34:44.334 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true
22:34:44.334 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false
22:34:44.334 INFO  MarkDuplicatesSpark - Deflater: IntelDeflater
22:34:44.334 INFO  MarkDuplicatesSpark - Inflater: IntelInflater
22:34:44.334 INFO  MarkDuplicatesSpark - GCS max retries/reopens: 20
22:34:44.334 INFO  MarkDuplicatesSpark - Requester pays: disabled
22:34:44.334 INFO  MarkDuplicatesSpark - Initializing engine
22:34:44.334 INFO  MarkDuplicatesSpark - Done initializing engine
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/12/26 22:34:44 INFO SparkContext: Running Spark version 2.4.5
22/12/26 22:34:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/12/26 22:34:45 INFO SparkContext: Submitted application: MarkDuplicatesSpark
22/12/26 22:34:45 INFO SecurityManager: Changing view acls to: vtimonin
22/12/26 22:34:45 INFO SecurityManager: Changing modify acls to: vtimonin
22/12/26 22:34:45 INFO SecurityManager: Changing view acls groups to: 
22/12/26 22:34:45 INFO SecurityManager: Changing modify acls groups to: 
22/12/26 22:34:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vtimonin); groups with view permissions: Set(); users  with modify permissions: Set(vtimonin); groups with modify permissions: Set()
22/12/26 22:34:45 INFO Utils: Successfully started service 'sparkDriver' on port 51578.
22/12/26 22:34:45 INFO SparkEnv: Registering MapOutputTracker
22/12/26 22:34:45 INFO SparkEnv: Registering BlockManagerMaster
22/12/26 22:34:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/12/26 22:34:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/12/26 22:34:45 INFO DiskBlockManager: Created local directory at /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmp4u3jifbf/blockmgr-31738a53-b1d0-4a2d-bb65-aebc3060287c
22/12/26 22:34:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
22/12/26 22:34:45 INFO SparkEnv: Registering OutputCommitCoordinator
22/12/26 22:34:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/12/26 22:34:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.22.22.136:4040
22/12/26 22:34:45 INFO Executor: Starting executor ID driver on host localhost
22/12/26 22:34:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51579.
22/12/26 22:34:46 INFO NettyBlockTransferService: Server created on 172.22.22.136:51579
22/12/26 22:34:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/12/26 22:34:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.22.22.136, 51579, None)
22/12/26 22:34:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.22.22.136:51579 with 366.3 MB RAM, BlockManagerId(driver, 172.22.22.136, 51579, None)
22/12/26 22:34:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.22.22.136, 51579, None)
22/12/26 22:34:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.22.22.136, 51579, None)
22:34:46.415 INFO  MarkDuplicatesSpark - Spark verbosity set to INFO (see --spark-verbosity argument)
22/12/26 22:34:46 INFO GoogleHadoopFileSystemBase: GHFS version: 1.9.4-hadoop3
22/12/26 22:34:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
22/12/26 22:34:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
22/12/26 22:34:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.22.22.136:51579 (size: 35.5 KB, free: 366.3 MB)
22/12/26 22:34:47 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96
22/12/26 22:34:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.22.22.136:51579 in memory (size: 35.5 KB, free: 366.3 MB)
22/12/26 22:34:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
22/12/26 22:34:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
22/12/26 22:34:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.22.22.136:51579 (size: 35.5 KB, free: 366.3 MB)
22/12/26 22:34:48 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96
22/12/26 22:34:48 INFO FileInputFormat: Total input files to process : 1
22/12/26 22:34:48 INFO SparkContext: Starting job: collect at SparkUtils.java:205
22/12/26 22:34:48 INFO DAGScheduler: Got job 0 (collect at SparkUtils.java:205) with 1 output partitions
22/12/26 22:34:48 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkUtils.java:205)
22/12/26 22:34:48 INFO DAGScheduler: Parents of final stage: List()
22/12/26 22:34:48 INFO DAGScheduler: Missing parents: List()
22/12/26 22:34:48 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188), which has no missing parents
22/12/26 22:34:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 249.3 KB, free 365.7 MB)
22/12/26 22:34:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 109.9 KB, free 365.6 MB)
22/12/26 22:34:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.22.22.136:51579 (size: 109.9 KB, free: 366.2 MB)
22/12/26 22:34:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
22/12/26 22:34:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7984 bytes)
22/12/26 22:34:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/12/26 22:34:49 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345678R_HJJLGCCXX_S1_L001.bam:0+2031197
22/12/26 22:34:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1570 bytes result sent to driver
22/12/26 22:34:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 326 ms on localhost (executor driver) (1/1)
22/12/26 22:34:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/12/26 22:34:49 INFO DAGScheduler: ResultStage 0 (collect at SparkUtils.java:205) finished in 0.480 s
22/12/26 22:34:49 INFO DAGScheduler: Job 0 finished: collect at SparkUtils.java:205, took 0.551986 s
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 45.0 B, free 365.6 MB)
22/12/26 22:34:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.22.22.136:51579 (size: 45.0 B, free: 366.2 MB)
22/12/26 22:34:49 INFO SparkContext: Created broadcast 3 from broadcast at MarkDuplicatesSparkUtils.java:126
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 44.0 B, free 365.6 MB)
22/12/26 22:34:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.22.22.136:51579 (size: 44.0 B, free: 366.2 MB)
22/12/26 22:34:49 INFO SparkContext: Created broadcast 4 from broadcast at MarkDuplicatesSparkUtils.java:127
22/12/26 22:34:49 INFO SparkContext: Starting job: collectAsMap at MarkDuplicatesSparkUtils.java:542
22/12/26 22:34:49 INFO DAGScheduler: Registering RDD 22 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) as input to shuffle 2
22/12/26 22:34:49 INFO DAGScheduler: Registering RDD 26 (mapToPair at MarkDuplicatesSpark.java:217) as input to shuffle 1
22/12/26 22:34:49 INFO DAGScheduler: Registering RDD 30 (mapToPair at MarkDuplicatesSparkUtils.java:497) as input to shuffle 0
22/12/26 22:34:49 INFO DAGScheduler: Got job 1 (collectAsMap at MarkDuplicatesSparkUtils.java:542) with 1 output partitions
22/12/26 22:34:49 INFO DAGScheduler: Final stage: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542)
22/12/26 22:34:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
22/12/26 22:34:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
22/12/26 22:34:49 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130), which has no missing parents
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 292.2 KB, free 365.3 MB)
22/12/26 22:34:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 126.4 KB, free 365.2 MB)
22/12/26 22:34:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.22.22.136:51579 (size: 126.4 KB, free: 366.0 MB)
22/12/26 22:34:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
22/12/26 22:34:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8432 bytes)
22/12/26 22:34:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
22/12/26 22:34:50 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345678R_HJJLGCCXX_S1_L001.bam:0+2031197
22:34:50.684 WARN  IntelInflater - Zero Bytes Written : 0
22/12/26 22:34:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 913 bytes result sent to driver
22/12/26 22:34:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 734 ms on localhost (executor driver) (1/1)
22/12/26 22:34:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
22/12/26 22:34:50 INFO DAGScheduler: ShuffleMapStage 1 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) finished in 0.812 s
22/12/26 22:34:50 INFO DAGScheduler: looking for newly runnable stages
22/12/26 22:34:50 INFO DAGScheduler: running: Set()
22/12/26 22:34:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, ResultStage 4)
22/12/26 22:34:50 INFO DAGScheduler: failed: Set()
22/12/26 22:34:50 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217), which has no missing parents
22/12/26 22:34:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 295.0 KB, free 364.9 MB)
22/12/26 22:34:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 127.9 KB, free 364.8 MB)
22/12/26 22:34:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.22.22.136:51579 (size: 127.9 KB, free: 365.9 MB)
22/12/26 22:34:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
22/12/26 22:34:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7651 bytes)
22/12/26 22:34:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
22/12/26 22:34:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
22/12/26 22:34:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 16
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 8
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 23
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 19
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 4
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 20
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 11
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 12
22/12/26 22:34:51 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.22.22.136:51579 in memory (size: 126.4 KB, free: 366.0 MB)
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 1
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 13
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 15
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 18
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 21
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 10
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 2
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 14
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 5
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 24
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 9
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 3
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 22
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 17
22/12/26 22:34:51 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.22.22.136:51579 in memory (size: 109.9 KB, free: 366.1 MB)
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 0
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 7
22/12/26 22:34:51 INFO ContextCleaner: Cleaned accumulator 6
22/12/26 22:34:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1300 bytes result sent to driver
22/12/26 22:34:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 800 ms on localhost (executor driver) (1/1)
22/12/26 22:34:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
22/12/26 22:34:51 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at MarkDuplicatesSpark.java:217) finished in 0.885 s
22/12/26 22:34:51 INFO DAGScheduler: looking for newly runnable stages
22/12/26 22:34:51 INFO DAGScheduler: running: Set()
22/12/26 22:34:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
22/12/26 22:34:51 INFO DAGScheduler: failed: Set()
22/12/26 22:34:51 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497), which has no missing parents
22/12/26 22:34:51 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 276.7 KB, free 365.3 MB)
22/12/26 22:34:51 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.7 KB, free 365.2 MB)
22/12/26 22:34:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.22.22.136:51579 (size: 120.7 KB, free: 366.0 MB)
22/12/26 22:34:51 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
22/12/26 22:34:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 8539 bytes)
22/12/26 22:34:51 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
22/12/26 22:34:51 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345678R_HJJLGCCXX_S1_L001.bam:0+2031197
22/12/26 22:34:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
22/12/26 22:34:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22:34:52.686 WARN  IntelInflater - Zero Bytes Written : 0
22/12/26 22:34:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1343 bytes result sent to driver
22/12/26 22:34:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1001 ms on localhost (executor driver) (1/1)
22/12/26 22:34:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
22/12/26 22:34:52 INFO DAGScheduler: ShuffleMapStage 3 (mapToPair at MarkDuplicatesSparkUtils.java:497) finished in 1.083 s
22/12/26 22:34:52 INFO DAGScheduler: looking for newly runnable stages
22/12/26 22:34:52 INFO DAGScheduler: running: Set()
22/12/26 22:34:52 INFO DAGScheduler: waiting: Set(ResultStage 4)
22/12/26 22:34:52 INFO DAGScheduler: failed: Set()
22/12/26 22:34:52 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519), which has no missing parents
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 277.5 KB, free 364.9 MB)
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 121.2 KB, free 364.8 MB)
22/12/26 22:34:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.22.22.136:51579 (size: 121.2 KB, free: 365.9 MB)
22/12/26 22:34:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:52 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
22/12/26 22:34:52 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 7662 bytes)
22/12/26 22:34:52 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
22/12/26 22:34:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
22/12/26 22:34:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/12/26 22:34:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1275 bytes result sent to driver
22/12/26 22:34:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 82 ms on localhost (executor driver) (1/1)
22/12/26 22:34:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
22/12/26 22:34:52 INFO DAGScheduler: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542) finished in 0.155 s
22/12/26 22:34:52 INFO DAGScheduler: Job 1 finished: collectAsMap at MarkDuplicatesSparkUtils.java:542, took 2.986825 s
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 43
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 84
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 87
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 119
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 40
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 115
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 35
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 52
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 73
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 108
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 78
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 58
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 80
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 99
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 68
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 60
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 104
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 33
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 85
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 74
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 59
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 96
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 116
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 76
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 124
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 47
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 79
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 102
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 88
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 61
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 36
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 63
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 103
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 123
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 30
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 50
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 120
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 117
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 92
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 95
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 46
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 39
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 70
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 38
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 44
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 54
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 66
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 97
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 106
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 101
22/12/26 22:34:52 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.22.22.136:51579 in memory (size: 127.9 KB, free: 366.0 MB)
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 121
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 77
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 27
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 105
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 122
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 32
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 55
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 83
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 31
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 71
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 45
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 51
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 110
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 69
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 57
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 25
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 62
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 56
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 81
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 93
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 75
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 109
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 41
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 107
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 42
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 90
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 113
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 29
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 49
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 86
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 91
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 82
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 26
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 48
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 89
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 34
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 100
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 72
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 118
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 114
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 65
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 53
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 67
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 28
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 94
22/12/26 22:34:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.22.22.136:51579 in memory (size: 121.2 KB, free: 366.1 MB)
22/12/26 22:34:52 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.22.22.136:51579 in memory (size: 120.7 KB, free: 366.3 MB)
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 111
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 37
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 112
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 98
22/12/26 22:34:52 INFO ContextCleaner: Cleaned accumulator 64
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 62.0 KB, free 365.9 MB)
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.9 MB)
22/12/26 22:34:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.22.22.136:51579 (size: 4.1 KB, free: 366.3 MB)
22/12/26 22:34:52 INFO SparkContext: Created broadcast 9 from broadcast at ReadsSparkSink.java:146
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 62.0 KB, free 365.8 MB)
22/12/26 22:34:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.8 MB)
22/12/26 22:34:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.22.22.136:51579 (size: 4.1 KB, free: 366.3 MB)
22/12/26 22:34:52 INFO SparkContext: Created broadcast 10 from broadcast at BamSink.java:76
22/12/26 22:34:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
22/12/26 22:34:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
22/12/26 22:34:53 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
22/12/26 22:34:53 INFO DAGScheduler: Registering RDD 34 (mapToPair at SparkUtils.java:161) as input to shuffle 3
22/12/26 22:34:53 INFO DAGScheduler: Got job 2 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
22/12/26 22:34:53 INFO DAGScheduler: Final stage: ResultStage 8 (runJob at SparkHadoopWriter.scala:78)
22/12/26 22:34:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
22/12/26 22:34:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
22/12/26 22:34:53 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161), which has no missing parents
22/12/26 22:34:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 275.7 KB, free 365.6 MB)
22/12/26 22:34:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.3 KB, free 365.4 MB)
22/12/26 22:34:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.22.22.136:51579 (size: 120.3 KB, free: 366.1 MB)
22/12/26 22:34:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:53 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
22/12/26 22:34:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, localhost, executor driver, partition 0, ANY, 8539 bytes)
22/12/26 22:34:53 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
22/12/26 22:34:53 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345678R_HJJLGCCXX_S1_L001.bam:0+2031197
22/12/26 22:34:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
22/12/26 22:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22:34:53.706 WARN  IntelInflater - Zero Bytes Written : 0
22/12/26 22:34:53 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 1214 bytes result sent to driver
22/12/26 22:34:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 592 ms on localhost (executor driver) (1/1)
22/12/26 22:34:53 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
22/12/26 22:34:53 INFO DAGScheduler: ShuffleMapStage 7 (mapToPair at SparkUtils.java:161) finished in 0.664 s
22/12/26 22:34:53 INFO DAGScheduler: looking for newly runnable stages
22/12/26 22:34:53 INFO DAGScheduler: running: Set()
22/12/26 22:34:53 INFO DAGScheduler: waiting: Set(ResultStage 8)
22/12/26 22:34:53 INFO DAGScheduler: failed: Set()
22/12/26 22:34:53 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91), which has no missing parents
22/12/26 22:34:53 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 108.8 KB, free 365.3 MB)
22/12/26 22:34:53 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.4 KB, free 365.3 MB)
22/12/26 22:34:53 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.22.22.136:51579 (size: 47.4 KB, free: 366.1 MB)
22/12/26 22:34:53 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1163
22/12/26 22:34:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91) (first 15 tasks are for partitions Vector(0))
22/12/26 22:34:53 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
22/12/26 22:34:53 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6, localhost, executor driver, partition 0, ANY, 7662 bytes)
22/12/26 22:34:53 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
22/12/26 22:34:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
22/12/26 22:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/12/26 22:34:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
22/12/26 22:34:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
22/12/26 22:34:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
22/12/26 22:34:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
22/12/26 22:34:54 INFO FileOutputCommitter: Saved output of task 'attempt_20221226223452_0039_r_000000_0' to file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam.parts
22/12/26 22:34:54 INFO SparkHadoopMapRedUtil: attempt_20221226223452_0039_r_000000_0: Committed
22/12/26 22:34:54 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1192 bytes result sent to driver
22/12/26 22:34:54 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 502 ms on localhost (executor driver) (1/1)
22/12/26 22:34:54 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
22/12/26 22:34:54 INFO DAGScheduler: ResultStage 8 (runJob at SparkHadoopWriter.scala:78) finished in 0.539 s
22/12/26 22:34:54 INFO DAGScheduler: Job 2 finished: runJob at SparkHadoopWriter.scala:78, took 1.211319 s
22/12/26 22:34:54 INFO SparkHadoopWriter: Job job_20221226223452_0039 committed.
22/12/26 22:34:54 INFO HadoopFileSystemWrapper: Concatenating 3 parts to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam
22/12/26 22:34:54 INFO HadoopFileSystemWrapper: Concatenating to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam done
22/12/26 22:34:54 INFO IndexFileMerger: Merging .sbi files in temp directory ../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam.sbi
22/12/26 22:34:54 INFO IndexFileMerger: Done merging .sbi files
22/12/26 22:34:54 INFO IndexFileMerger: Merging .bai files in temp directory ../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345678R_HJJLGCCXX_S1_L001.dedup.bam.bai
22/12/26 22:34:54 INFO IndexFileMerger: Done merging .bai files
22/12/26 22:34:54 INFO SparkUI: Stopped Spark web UI at http://172.22.22.136:4040
22/12/26 22:34:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/12/26 22:34:54 INFO MemoryStore: MemoryStore cleared
22/12/26 22:34:54 INFO BlockManager: BlockManager stopped
22/12/26 22:34:54 INFO BlockManagerMaster: BlockManagerMaster stopped
22/12/26 22:34:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/12/26 22:34:54 INFO SparkContext: Successfully stopped SparkContext
22:34:54.620 INFO  MarkDuplicatesSpark - Shutting down engine
[December 26, 2022 10:34:54 PM CET] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.18 minutes.
Runtime.totalMemory()=425721856
22/12/26 22:34:54 INFO ShutdownHookManager: Shutdown hook called
22/12/26 22:34:54 INFO ShutdownHookManager: Deleting directory /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmp4u3jifbf/spark-35217e90-a3fd-4610-b9d8-4f47ee201370
