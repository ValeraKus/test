Using GATK jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar
Running:
    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1024M -jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar MarkDuplicatesSpark --input ../interim/CPCT12345680R_HJJLGCCXX_S1_L001.bam --tmp-dir /var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmpb2f1p9a_ --output ../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam --metrics-file ../interim/CPCT12345680R_HJJLGCCXX_S1_L001.metrics.txt --spark-master local[1]
11:52:48.542 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib
11:52:49.022 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:49.023 INFO  MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0
11:52:49.023 INFO  MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/
11:52:49.023 INFO  MarkDuplicatesSpark - Executing as vtimonin@SV-66M-004 on Mac OS X v10.16 x86_64
11:52:49.024 INFO  MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12
11:52:49.024 INFO  MarkDuplicatesSpark - Start Date/Time: January 3, 2023 11:52:48 AM CET
11:52:49.024 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:49.024 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:49.024 INFO  MarkDuplicatesSpark - HTSJDK Version: 3.0.1
11:52:49.025 INFO  MarkDuplicatesSpark - Picard Version: 2.27.5
11:52:49.025 INFO  MarkDuplicatesSpark - Built for Spark Version: 2.4.5
11:52:49.025 INFO  MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2
11:52:49.025 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false
11:52:49.025 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true
11:52:49.025 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false
11:52:49.025 INFO  MarkDuplicatesSpark - Deflater: IntelDeflater
11:52:49.025 INFO  MarkDuplicatesSpark - Inflater: IntelInflater
11:52:49.025 INFO  MarkDuplicatesSpark - GCS max retries/reopens: 20
11:52:49.025 INFO  MarkDuplicatesSpark - Requester pays: disabled
11:52:49.025 INFO  MarkDuplicatesSpark - Initializing engine
11:52:49.025 INFO  MarkDuplicatesSpark - Done initializing engine
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/01/03 11:52:49 INFO SparkContext: Running Spark version 2.4.5
23/01/03 11:52:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/03 11:52:49 INFO SparkContext: Submitted application: MarkDuplicatesSpark
23/01/03 11:52:50 INFO SecurityManager: Changing view acls to: vtimonin
23/01/03 11:52:50 INFO SecurityManager: Changing modify acls to: vtimonin
23/01/03 11:52:50 INFO SecurityManager: Changing view acls groups to: 
23/01/03 11:52:50 INFO SecurityManager: Changing modify acls groups to: 
23/01/03 11:52:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vtimonin); groups with view permissions: Set(); users  with modify permissions: Set(vtimonin); groups with modify permissions: Set()
23/01/03 11:52:50 INFO Utils: Successfully started service 'sparkDriver' on port 52949.
23/01/03 11:52:50 INFO SparkEnv: Registering MapOutputTracker
23/01/03 11:52:50 INFO SparkEnv: Registering BlockManagerMaster
23/01/03 11:52:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/03 11:52:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/03 11:52:50 INFO DiskBlockManager: Created local directory at /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmpb2f1p9a_/blockmgr-4c751de7-a445-4762-88a0-00e86eeb636d
23/01/03 11:52:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
23/01/03 11:52:50 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/03 11:52:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/03 11:52:51 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tsf-492-wpa-2-052.epfl.ch:4040
23/01/03 11:52:51 INFO Executor: Starting executor ID driver on host localhost
23/01/03 11:52:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52950.
23/01/03 11:52:51 INFO NettyBlockTransferService: Server created on tsf-492-wpa-2-052.epfl.ch:52950
23/01/03 11:52:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/03 11:52:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52950, None)
23/01/03 11:52:51 INFO BlockManagerMasterEndpoint: Registering block manager tsf-492-wpa-2-052.epfl.ch:52950 with 366.3 MB RAM, BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52950, None)
23/01/03 11:52:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52950, None)
23/01/03 11:52:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52950, None)
11:52:52.478 INFO  MarkDuplicatesSpark - Spark verbosity set to INFO (see --spark-verbosity argument)
23/01/03 11:52:52 INFO GoogleHadoopFileSystemBase: GHFS version: 1.9.4-hadoop3
23/01/03 11:52:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
23/01/03 11:52:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
23/01/03 11:52:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:54 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96
23/01/03 11:52:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
23/01/03 11:52:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
23/01/03 11:52:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:55 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96
23/01/03 11:52:55 INFO FileInputFormat: Total input files to process : 1
23/01/03 11:52:55 INFO SparkContext: Starting job: collect at SparkUtils.java:205
23/01/03 11:52:55 INFO DAGScheduler: Got job 0 (collect at SparkUtils.java:205) with 1 output partitions
23/01/03 11:52:55 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkUtils.java:205)
23/01/03 11:52:55 INFO DAGScheduler: Parents of final stage: List()
23/01/03 11:52:55 INFO DAGScheduler: Missing parents: List()
23/01/03 11:52:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188), which has no missing parents
23/01/03 11:52:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 249.3 KB, free 365.7 MB)
23/01/03 11:52:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 109.9 KB, free 365.6 MB)
23/01/03 11:52:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 109.9 KB, free: 366.2 MB)
23/01/03 11:52:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
23/01/03 11:52:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7984 bytes)
23/01/03 11:52:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/01/03 11:52:56 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345680R_HJJLGCCXX_S1_L001.bam:0+2031198
23/01/03 11:52:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1527 bytes result sent to driver
23/01/03 11:52:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 300 ms on localhost (executor driver) (1/1)
23/01/03 11:52:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/01/03 11:52:56 INFO DAGScheduler: ResultStage 0 (collect at SparkUtils.java:205) finished in 0.443 s
23/01/03 11:52:56 INFO DAGScheduler: Job 0 finished: collect at SparkUtils.java:205, took 0.503727 s
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 45.0 B, free 365.6 MB)
23/01/03 11:52:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 45.0 B, free: 366.2 MB)
23/01/03 11:52:56 INFO SparkContext: Created broadcast 3 from broadcast at MarkDuplicatesSparkUtils.java:126
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 4
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 19
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 13
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 9
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 14
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 21
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 17
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 16
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 1
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 3
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 7
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 22
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 11
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 18
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 5
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 8
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 24
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 6
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 0
23/01/03 11:52:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 109.9 KB, free: 366.3 MB)
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 10
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 12
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 23
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 2
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 15
23/01/03 11:52:56 INFO ContextCleaner: Cleaned accumulator 20
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 44.0 B, free 366.0 MB)
23/01/03 11:52:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 44.0 B, free: 366.3 MB)
23/01/03 11:52:56 INFO SparkContext: Created broadcast 4 from broadcast at MarkDuplicatesSparkUtils.java:127
23/01/03 11:52:56 INFO SparkContext: Starting job: collectAsMap at MarkDuplicatesSparkUtils.java:542
23/01/03 11:52:56 INFO DAGScheduler: Registering RDD 22 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) as input to shuffle 2
23/01/03 11:52:56 INFO DAGScheduler: Registering RDD 26 (mapToPair at MarkDuplicatesSpark.java:217) as input to shuffle 1
23/01/03 11:52:56 INFO DAGScheduler: Registering RDD 30 (mapToPair at MarkDuplicatesSparkUtils.java:497) as input to shuffle 0
23/01/03 11:52:56 INFO DAGScheduler: Got job 1 (collectAsMap at MarkDuplicatesSparkUtils.java:542) with 1 output partitions
23/01/03 11:52:56 INFO DAGScheduler: Final stage: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542)
23/01/03 11:52:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
23/01/03 11:52:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
23/01/03 11:52:56 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130), which has no missing parents
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 292.2 KB, free 365.7 MB)
23/01/03 11:52:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 126.4 KB, free 365.6 MB)
23/01/03 11:52:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 126.4 KB, free: 366.1 MB)
23/01/03 11:52:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
23/01/03 11:52:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8432 bytes)
23/01/03 11:52:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/01/03 11:52:57 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345680R_HJJLGCCXX_S1_L001.bam:0+2031198
11:52:57.629 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:52:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 925 bytes result sent to driver
23/01/03 11:52:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 777 ms on localhost (executor driver) (1/1)
23/01/03 11:52:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/01/03 11:52:57 INFO DAGScheduler: ShuffleMapStage 1 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) finished in 0.855 s
23/01/03 11:52:57 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:57 INFO DAGScheduler: running: Set()
23/01/03 11:52:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, ResultStage 4)
23/01/03 11:52:57 INFO DAGScheduler: failed: Set()
23/01/03 11:52:57 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217), which has no missing parents
23/01/03 11:52:57 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 295.0 KB, free 365.3 MB)
23/01/03 11:52:57 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 127.9 KB, free 365.1 MB)
23/01/03 11:52:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 127.9 KB, free: 366.0 MB)
23/01/03 11:52:57 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
23/01/03 11:52:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7651 bytes)
23/01/03 11:52:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/01/03 11:52:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
23/01/03 11:52:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1312 bytes result sent to driver
23/01/03 11:52:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 815 ms on localhost (executor driver) (1/1)
23/01/03 11:52:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/01/03 11:52:58 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at MarkDuplicatesSpark.java:217) finished in 0.899 s
23/01/03 11:52:58 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:58 INFO DAGScheduler: running: Set()
23/01/03 11:52:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
23/01/03 11:52:58 INFO DAGScheduler: failed: Set()
23/01/03 11:52:58 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497), which has no missing parents
23/01/03 11:52:58 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 276.7 KB, free 364.9 MB)
23/01/03 11:52:58 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.7 KB, free 364.8 MB)
23/01/03 11:52:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 120.7 KB, free: 365.9 MB)
23/01/03 11:52:58 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
23/01/03 11:52:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 8539 bytes)
23/01/03 11:52:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/01/03 11:52:58 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345680R_HJJLGCCXX_S1_L001.bam:0+2031198
23/01/03 11:52:58 INFO BlockManagerInfo: Removed broadcast_5_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 126.4 KB, free: 366.0 MB)
23/01/03 11:52:58 INFO BlockManagerInfo: Removed broadcast_6_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 127.9 KB, free: 366.1 MB)
23/01/03 11:52:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
11:52:59.421 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:52:59 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1441 bytes result sent to driver
23/01/03 11:52:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 774 ms on localhost (executor driver) (1/1)
23/01/03 11:52:59 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/01/03 11:52:59 INFO DAGScheduler: ShuffleMapStage 3 (mapToPair at MarkDuplicatesSparkUtils.java:497) finished in 0.854 s
23/01/03 11:52:59 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:59 INFO DAGScheduler: running: Set()
23/01/03 11:52:59 INFO DAGScheduler: waiting: Set(ResultStage 4)
23/01/03 11:52:59 INFO DAGScheduler: failed: Set()
23/01/03 11:52:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519), which has no missing parents
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 277.5 KB, free 365.3 MB)
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 121.2 KB, free 365.2 MB)
23/01/03 11:52:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 121.2 KB, free: 366.0 MB)
23/01/03 11:52:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:59 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
23/01/03 11:52:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 7662 bytes)
23/01/03 11:52:59 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/01/03 11:52:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/01/03 11:52:59 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1275 bytes result sent to driver
23/01/03 11:52:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 74 ms on localhost (executor driver) (1/1)
23/01/03 11:52:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/01/03 11:52:59 INFO DAGScheduler: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542) finished in 0.149 s
23/01/03 11:52:59 INFO DAGScheduler: Job 1 finished: collectAsMap at MarkDuplicatesSparkUtils.java:542, took 2.810154 s
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 62.0 KB, free 365.1 MB)
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.1 MB)
23/01/03 11:52:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 4.1 KB, free: 366.0 MB)
23/01/03 11:52:59 INFO SparkContext: Created broadcast 9 from broadcast at ReadsSparkSink.java:146
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 62.0 KB, free 365.1 MB)
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.1 MB)
23/01/03 11:52:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 4.1 KB, free: 366.0 MB)
23/01/03 11:52:59 INFO SparkContext: Created broadcast 10 from broadcast at BamSink.java:76
23/01/03 11:52:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:52:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:52:59 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
23/01/03 11:52:59 INFO DAGScheduler: Registering RDD 34 (mapToPair at SparkUtils.java:161) as input to shuffle 3
23/01/03 11:52:59 INFO DAGScheduler: Got job 2 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
23/01/03 11:52:59 INFO DAGScheduler: Final stage: ResultStage 8 (runJob at SparkHadoopWriter.scala:78)
23/01/03 11:52:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
23/01/03 11:52:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
23/01/03 11:52:59 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161), which has no missing parents
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 275.7 KB, free 364.8 MB)
23/01/03 11:52:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.3 KB, free 364.7 MB)
23/01/03 11:52:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 120.3 KB, free: 365.9 MB)
23/01/03 11:52:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:59 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
23/01/03 11:52:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, localhost, executor driver, partition 0, ANY, 8539 bytes)
23/01/03 11:52:59 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
23/01/03 11:52:59 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345680R_HJJLGCCXX_S1_L001.bam:0+2031198
23/01/03 11:52:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 87
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 27
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 120
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 43
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 94
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 25
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 121
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 50
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 45
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 88
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 33
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 78
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 28
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 40
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 77
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 44
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 123
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 112
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 79
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 31
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 54
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 89
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 39
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 92
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 107
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 35
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 115
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 36
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 100
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 102
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 118
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 57
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 66
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 51
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 101
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 71
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 42
23/01/03 11:53:00 INFO ContextCleaner: Cleaned shuffle 0
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 47
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 93
23/01/03 11:53:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 120.7 KB, free: 366.0 MB)
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 49
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 108
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 95
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 60
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 38
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 116
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 124
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 29
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 122
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 69
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 105
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 111
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 103
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 76
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 84
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 83
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 90
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 64
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 73
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 96
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 97
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 46
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 80
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 99
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 58
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 55
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 62
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 119
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 26
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 53
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 75
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 98
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 106
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 104
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 86
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 82
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 65
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 109
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 74
23/01/03 11:53:00 INFO BlockManagerInfo: Removed broadcast_8_piece0 on tsf-492-wpa-2-052.epfl.ch:52950 in memory (size: 121.2 KB, free: 366.1 MB)
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 48
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 81
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 72
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 110
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 59
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 114
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 117
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 85
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 91
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 41
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 56
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 52
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 32
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 63
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 68
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 113
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 61
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 37
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 34
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 70
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 30
23/01/03 11:53:00 INFO ContextCleaner: Cleaned accumulator 67
11:53:00.411 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:53:00 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 1312 bytes result sent to driver
23/01/03 11:53:00 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 541 ms on localhost (executor driver) (1/1)
23/01/03 11:53:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/01/03 11:53:00 INFO DAGScheduler: ShuffleMapStage 7 (mapToPair at SparkUtils.java:161) finished in 0.622 s
23/01/03 11:53:00 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:53:00 INFO DAGScheduler: running: Set()
23/01/03 11:53:00 INFO DAGScheduler: waiting: Set(ResultStage 8)
23/01/03 11:53:00 INFO DAGScheduler: failed: Set()
23/01/03 11:53:00 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91), which has no missing parents
23/01/03 11:53:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 108.8 KB, free 365.3 MB)
23/01/03 11:53:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.4 KB, free 365.3 MB)
23/01/03 11:53:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52950 (size: 47.4 KB, free: 366.1 MB)
23/01/03 11:53:00 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1163
23/01/03 11:53:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91) (first 15 tasks are for partitions Vector(0))
23/01/03 11:53:00 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
23/01/03 11:53:00 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6, localhost, executor driver, partition 0, ANY, 7662 bytes)
23/01/03 11:53:00 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
23/01/03 11:53:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:53:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/01/03 11:53:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:53:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:53:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:53:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:53:01 INFO FileOutputCommitter: Saved output of task 'attempt_20230103115259_0039_r_000000_0' to file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam.parts
23/01/03 11:53:01 INFO SparkHadoopMapRedUtil: attempt_20230103115259_0039_r_000000_0: Committed
23/01/03 11:53:01 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1192 bytes result sent to driver
23/01/03 11:53:01 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 697 ms on localhost (executor driver) (1/1)
23/01/03 11:53:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/01/03 11:53:01 INFO DAGScheduler: ResultStage 8 (runJob at SparkHadoopWriter.scala:78) finished in 0.738 s
23/01/03 11:53:01 INFO DAGScheduler: Job 2 finished: runJob at SparkHadoopWriter.scala:78, took 1.368089 s
23/01/03 11:53:01 INFO SparkHadoopWriter: Job job_20230103115259_0039 committed.
23/01/03 11:53:01 INFO HadoopFileSystemWrapper: Concatenating 3 parts to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam
23/01/03 11:53:01 INFO HadoopFileSystemWrapper: Concatenating to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam done
23/01/03 11:53:01 INFO IndexFileMerger: Merging .sbi files in temp directory ../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam.sbi
23/01/03 11:53:01 INFO IndexFileMerger: Done merging .sbi files
23/01/03 11:53:01 INFO IndexFileMerger: Merging .bai files in temp directory ../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345680R_HJJLGCCXX_S1_L001.dedup.bam.bai
23/01/03 11:53:01 INFO IndexFileMerger: Done merging .bai files
23/01/03 11:53:01 INFO SparkUI: Stopped Spark web UI at http://tsf-492-wpa-2-052.epfl.ch:4040
23/01/03 11:53:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/03 11:53:01 INFO MemoryStore: MemoryStore cleared
23/01/03 11:53:01 INFO BlockManager: BlockManager stopped
23/01/03 11:53:01 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/03 11:53:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/03 11:53:01 INFO SparkContext: Successfully stopped SparkContext
11:53:01.550 INFO  MarkDuplicatesSpark - Shutting down engine
[January 3, 2023 11:53:01 AM CET] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.22 minutes.
Runtime.totalMemory()=435683328
23/01/03 11:53:01 INFO ShutdownHookManager: Shutdown hook called
23/01/03 11:53:01 INFO ShutdownHookManager: Deleting directory /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmpb2f1p9a_/spark-1a8ad638-c466-45e9-aa94-ea44e5d5db5f
