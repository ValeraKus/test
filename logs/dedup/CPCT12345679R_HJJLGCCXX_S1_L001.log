Using GATK jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar
Running:
    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1024M -jar /Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar MarkDuplicatesSpark --input ../interim/CPCT12345679R_HJJLGCCXX_S1_L001.bam --tmp-dir /var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmppyk8zsur --output ../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam --metrics-file ../interim/CPCT12345679R_HJJLGCCXX_S1_L001.metrics.txt --spark-master local[1]
11:52:01.047 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/vtimonin/opt/anaconda3/envs/snakemake/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib
11:52:01.422 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:01.422 INFO  MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0
11:52:01.422 INFO  MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/
11:52:01.423 INFO  MarkDuplicatesSpark - Executing as vtimonin@SV-66M-004 on Mac OS X v10.16 x86_64
11:52:01.423 INFO  MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12
11:52:01.423 INFO  MarkDuplicatesSpark - Start Date/Time: January 3, 2023 11:52:01 AM CET
11:52:01.423 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:01.423 INFO  MarkDuplicatesSpark - ------------------------------------------------------------
11:52:01.424 INFO  MarkDuplicatesSpark - HTSJDK Version: 3.0.1
11:52:01.424 INFO  MarkDuplicatesSpark - Picard Version: 2.27.5
11:52:01.424 INFO  MarkDuplicatesSpark - Built for Spark Version: 2.4.5
11:52:01.424 INFO  MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2
11:52:01.424 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false
11:52:01.424 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true
11:52:01.424 INFO  MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false
11:52:01.424 INFO  MarkDuplicatesSpark - Deflater: IntelDeflater
11:52:01.424 INFO  MarkDuplicatesSpark - Inflater: IntelInflater
11:52:01.424 INFO  MarkDuplicatesSpark - GCS max retries/reopens: 20
11:52:01.424 INFO  MarkDuplicatesSpark - Requester pays: disabled
11:52:01.424 INFO  MarkDuplicatesSpark - Initializing engine
11:52:01.424 INFO  MarkDuplicatesSpark - Done initializing engine
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/01/03 11:52:01 INFO SparkContext: Running Spark version 2.4.5
23/01/03 11:52:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/03 11:52:02 INFO SparkContext: Submitted application: MarkDuplicatesSpark
23/01/03 11:52:02 INFO SecurityManager: Changing view acls to: vtimonin
23/01/03 11:52:02 INFO SecurityManager: Changing modify acls to: vtimonin
23/01/03 11:52:02 INFO SecurityManager: Changing view acls groups to: 
23/01/03 11:52:02 INFO SecurityManager: Changing modify acls groups to: 
23/01/03 11:52:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vtimonin); groups with view permissions: Set(); users  with modify permissions: Set(vtimonin); groups with modify permissions: Set()
23/01/03 11:52:02 INFO Utils: Successfully started service 'sparkDriver' on port 52923.
23/01/03 11:52:02 INFO SparkEnv: Registering MapOutputTracker
23/01/03 11:52:02 INFO SparkEnv: Registering BlockManagerMaster
23/01/03 11:52:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/03 11:52:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/03 11:52:02 INFO DiskBlockManager: Created local directory at /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmppyk8zsur/blockmgr-8d5ce211-31ef-4a04-84e3-89a8fc257e41
23/01/03 11:52:02 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
23/01/03 11:52:02 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/03 11:52:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/03 11:52:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tsf-492-wpa-2-052.epfl.ch:4040
23/01/03 11:52:03 INFO Executor: Starting executor ID driver on host localhost
23/01/03 11:52:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52924.
23/01/03 11:52:03 INFO NettyBlockTransferService: Server created on tsf-492-wpa-2-052.epfl.ch:52924
23/01/03 11:52:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/03 11:52:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52924, None)
23/01/03 11:52:03 INFO BlockManagerMasterEndpoint: Registering block manager tsf-492-wpa-2-052.epfl.ch:52924 with 366.3 MB RAM, BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52924, None)
23/01/03 11:52:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52924, None)
23/01/03 11:52:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, tsf-492-wpa-2-052.epfl.ch, 52924, None)
11:52:03.699 INFO  MarkDuplicatesSpark - Spark verbosity set to INFO (see --spark-verbosity argument)
23/01/03 11:52:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.9.4-hadoop3
23/01/03 11:52:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
23/01/03 11:52:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
23/01/03 11:52:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:05 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96
23/01/03 11:52:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on tsf-492-wpa-2-052.epfl.ch:52924 in memory (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 308.1 KB, free 366.0 MB)
23/01/03 11:52:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.5 KB, free 366.0 MB)
23/01/03 11:52:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 35.5 KB, free: 366.3 MB)
23/01/03 11:52:06 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96
23/01/03 11:52:06 INFO FileInputFormat: Total input files to process : 1
23/01/03 11:52:07 INFO SparkContext: Starting job: collect at SparkUtils.java:205
23/01/03 11:52:07 INFO DAGScheduler: Got job 0 (collect at SparkUtils.java:205) with 1 output partitions
23/01/03 11:52:07 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkUtils.java:205)
23/01/03 11:52:07 INFO DAGScheduler: Parents of final stage: List()
23/01/03 11:52:07 INFO DAGScheduler: Missing parents: List()
23/01/03 11:52:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188), which has no missing parents
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 249.3 KB, free 365.7 MB)
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 109.9 KB, free 365.6 MB)
23/01/03 11:52:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 109.9 KB, free: 366.2 MB)
23/01/03 11:52:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[12] at mapPartitions at SparkUtils.java:188) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
23/01/03 11:52:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7984 bytes)
23/01/03 11:52:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/01/03 11:52:07 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345679R_HJJLGCCXX_S1_L001.bam:0+2031183
23/01/03 11:52:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1527 bytes result sent to driver
23/01/03 11:52:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 347 ms on localhost (executor driver) (1/1)
23/01/03 11:52:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/01/03 11:52:07 INFO DAGScheduler: ResultStage 0 (collect at SparkUtils.java:205) finished in 0.548 s
23/01/03 11:52:07 INFO DAGScheduler: Job 0 finished: collect at SparkUtils.java:205, took 0.622828 s
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 45.0 B, free 365.6 MB)
23/01/03 11:52:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 45.0 B, free: 366.2 MB)
23/01/03 11:52:07 INFO SparkContext: Created broadcast 3 from broadcast at MarkDuplicatesSparkUtils.java:126
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 192.0 B, free 365.6 MB)
23/01/03 11:52:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 44.0 B, free 365.6 MB)
23/01/03 11:52:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 44.0 B, free: 366.2 MB)
23/01/03 11:52:07 INFO SparkContext: Created broadcast 4 from broadcast at MarkDuplicatesSparkUtils.java:127
23/01/03 11:52:08 INFO SparkContext: Starting job: collectAsMap at MarkDuplicatesSparkUtils.java:542
23/01/03 11:52:08 INFO DAGScheduler: Registering RDD 22 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) as input to shuffle 2
23/01/03 11:52:08 INFO DAGScheduler: Registering RDD 26 (mapToPair at MarkDuplicatesSpark.java:217) as input to shuffle 1
23/01/03 11:52:08 INFO DAGScheduler: Registering RDD 30 (mapToPair at MarkDuplicatesSparkUtils.java:497) as input to shuffle 0
23/01/03 11:52:08 INFO DAGScheduler: Got job 1 (collectAsMap at MarkDuplicatesSparkUtils.java:542) with 1 output partitions
23/01/03 11:52:08 INFO DAGScheduler: Final stage: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542)
23/01/03 11:52:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
23/01/03 11:52:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
23/01/03 11:52:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130), which has no missing parents
23/01/03 11:52:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 292.2 KB, free 365.3 MB)
23/01/03 11:52:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 126.4 KB, free 365.2 MB)
23/01/03 11:52:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 126.4 KB, free: 366.0 MB)
23/01/03 11:52:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[22] at flatMapToPair at MarkDuplicatesSparkUtils.java:130) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
23/01/03 11:52:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8432 bytes)
23/01/03 11:52:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/01/03 11:52:08 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345679R_HJJLGCCXX_S1_L001.bam:0+2031183
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 17
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 20
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 14
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 6
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 22
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 19
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 1
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 15
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 23
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 4
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 24
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 0
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 10
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 21
23/01/03 11:52:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on tsf-492-wpa-2-052.epfl.ch:52924 in memory (size: 109.9 KB, free: 366.1 MB)
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 11
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 16
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 13
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 7
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 3
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 5
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 18
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 8
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 9
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 2
23/01/03 11:52:08 INFO ContextCleaner: Cleaned accumulator 12
11:52:09.200 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:52:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 968 bytes result sent to driver
23/01/03 11:52:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 719 ms on localhost (executor driver) (1/1)
23/01/03 11:52:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/01/03 11:52:09 INFO DAGScheduler: ShuffleMapStage 1 (flatMapToPair at MarkDuplicatesSparkUtils.java:130) finished in 0.794 s
23/01/03 11:52:09 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:09 INFO DAGScheduler: running: Set()
23/01/03 11:52:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, ResultStage 4)
23/01/03 11:52:09 INFO DAGScheduler: failed: Set()
23/01/03 11:52:09 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217), which has no missing parents
23/01/03 11:52:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 295.0 KB, free 365.3 MB)
23/01/03 11:52:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 127.9 KB, free 365.1 MB)
23/01/03 11:52:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 127.9 KB, free: 366.0 MB)
23/01/03 11:52:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[26] at mapToPair at MarkDuplicatesSpark.java:217) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
23/01/03 11:52:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7651 bytes)
23/01/03 11:52:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/01/03 11:52:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
23/01/03 11:52:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1269 bytes result sent to driver
23/01/03 11:52:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1028 ms on localhost (executor driver) (1/1)
23/01/03 11:52:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/01/03 11:52:10 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at MarkDuplicatesSpark.java:217) finished in 1.133 s
23/01/03 11:52:10 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:10 INFO DAGScheduler: running: Set()
23/01/03 11:52:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
23/01/03 11:52:10 INFO DAGScheduler: failed: Set()
23/01/03 11:52:10 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497), which has no missing parents
23/01/03 11:52:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 276.7 KB, free 364.9 MB)
23/01/03 11:52:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.7 KB, free 364.8 MB)
23/01/03 11:52:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 120.7 KB, free: 365.9 MB)
23/01/03 11:52:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[30] at mapToPair at MarkDuplicatesSparkUtils.java:497) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
23/01/03 11:52:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 8539 bytes)
23/01/03 11:52:10 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/01/03 11:52:10 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345679R_HJJLGCCXX_S1_L001.bam:0+2031183
23/01/03 11:52:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
11:52:12.791 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:52:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1355 bytes result sent to driver
23/01/03 11:52:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 2303 ms on localhost (executor driver) (1/1)
23/01/03 11:52:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/01/03 11:52:12 INFO DAGScheduler: ShuffleMapStage 3 (mapToPair at MarkDuplicatesSparkUtils.java:497) finished in 2.513 s
23/01/03 11:52:12 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:12 INFO DAGScheduler: running: Set()
23/01/03 11:52:12 INFO DAGScheduler: waiting: Set(ResultStage 4)
23/01/03 11:52:12 INFO DAGScheduler: failed: Set()
23/01/03 11:52:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519), which has no missing parents
23/01/03 11:52:12 INFO BlockManagerInfo: Removed broadcast_6_piece0 on tsf-492-wpa-2-052.epfl.ch:52924 in memory (size: 127.9 KB, free: 366.0 MB)
23/01/03 11:52:13 INFO BlockManagerInfo: Removed broadcast_5_piece0 on tsf-492-wpa-2-052.epfl.ch:52924 in memory (size: 126.4 KB, free: 366.1 MB)
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 277.5 KB, free 365.3 MB)
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 121.2 KB, free 365.2 MB)
23/01/03 11:52:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 121.2 KB, free: 366.0 MB)
23/01/03 11:52:13 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[32] at mapValues at MarkDuplicatesSparkUtils.java:519) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
23/01/03 11:52:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 7662 bytes)
23/01/03 11:52:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/01/03 11:52:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/01/03 11:52:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1275 bytes result sent to driver
23/01/03 11:52:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 203 ms on localhost (executor driver) (1/1)
23/01/03 11:52:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/01/03 11:52:13 INFO DAGScheduler: ResultStage 4 (collectAsMap at MarkDuplicatesSparkUtils.java:542) finished in 0.400 s
23/01/03 11:52:13 INFO DAGScheduler: Job 1 finished: collectAsMap at MarkDuplicatesSparkUtils.java:542, took 4.893881 s
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 62.0 KB, free 365.1 MB)
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.1 MB)
23/01/03 11:52:13 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 4.1 KB, free: 366.0 MB)
23/01/03 11:52:13 INFO SparkContext: Created broadcast 9 from broadcast at ReadsSparkSink.java:146
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 62.0 KB, free 365.1 MB)
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.1 MB)
23/01/03 11:52:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 4.1 KB, free: 366.0 MB)
23/01/03 11:52:13 INFO SparkContext: Created broadcast 10 from broadcast at BamSink.java:76
23/01/03 11:52:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:52:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:52:13 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
23/01/03 11:52:13 INFO DAGScheduler: Registering RDD 34 (mapToPair at SparkUtils.java:161) as input to shuffle 3
23/01/03 11:52:13 INFO DAGScheduler: Got job 2 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
23/01/03 11:52:13 INFO DAGScheduler: Final stage: ResultStage 8 (runJob at SparkHadoopWriter.scala:78)
23/01/03 11:52:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
23/01/03 11:52:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
23/01/03 11:52:13 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161), which has no missing parents
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 275.7 KB, free 364.8 MB)
23/01/03 11:52:13 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.3 KB, free 364.7 MB)
23/01/03 11:52:13 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 120.3 KB, free: 365.9 MB)
23/01/03 11:52:13 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[34] at mapToPair at SparkUtils.java:161) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:13 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
23/01/03 11:52:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, localhost, executor driver, partition 0, ANY, 8539 bytes)
23/01/03 11:52:13 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
23/01/03 11:52:14 INFO NewHadoopRDD: Input split: file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345679R_HJJLGCCXX_S1_L001.bam:0+2031183
23/01/03 11:52:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
11:52:15.479 WARN  IntelInflater - Zero Bytes Written : 0
23/01/03 11:52:15 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 1226 bytes result sent to driver
23/01/03 11:52:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 1554 ms on localhost (executor driver) (1/1)
23/01/03 11:52:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/01/03 11:52:15 INFO DAGScheduler: ShuffleMapStage 7 (mapToPair at SparkUtils.java:161) finished in 1.808 s
23/01/03 11:52:15 INFO DAGScheduler: looking for newly runnable stages
23/01/03 11:52:15 INFO DAGScheduler: running: Set()
23/01/03 11:52:15 INFO DAGScheduler: waiting: Set(ResultStage 8)
23/01/03 11:52:15 INFO DAGScheduler: failed: Set()
23/01/03 11:52:15 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91), which has no missing parents
23/01/03 11:52:15 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 108.8 KB, free 364.6 MB)
23/01/03 11:52:15 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.4 KB, free 364.5 MB)
23/01/03 11:52:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on tsf-492-wpa-2-052.epfl.ch:52924 (size: 47.4 KB, free: 365.9 MB)
23/01/03 11:52:15 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1163
23/01/03 11:52:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at mapToPair at BamSink.java:91) (first 15 tasks are for partitions Vector(0))
23/01/03 11:52:15 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
23/01/03 11:52:15 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6, localhost, executor driver, partition 0, ANY, 7662 bytes)
23/01/03 11:52:15 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
23/01/03 11:52:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
23/01/03 11:52:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/01/03 11:52:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:52:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:52:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
23/01/03 11:52:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/01/03 11:52:17 INFO FileOutputCommitter: Saved output of task 'attempt_20230103115213_0039_r_000000_0' to file:/Users/vtimonin/Desktop/Work/test/interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam.parts
23/01/03 11:52:17 INFO SparkHadoopMapRedUtil: attempt_20230103115213_0039_r_000000_0: Committed
23/01/03 11:52:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1192 bytes result sent to driver
23/01/03 11:52:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 1626 ms on localhost (executor driver) (1/1)
23/01/03 11:52:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/01/03 11:52:17 INFO DAGScheduler: ResultStage 8 (runJob at SparkHadoopWriter.scala:78) finished in 1.694 s
23/01/03 11:52:17 INFO DAGScheduler: Job 2 finished: runJob at SparkHadoopWriter.scala:78, took 3.518420 s
23/01/03 11:52:17 INFO SparkHadoopWriter: Job job_20230103115213_0039 committed.
23/01/03 11:52:17 INFO HadoopFileSystemWrapper: Concatenating 3 parts to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam
23/01/03 11:52:17 INFO HadoopFileSystemWrapper: Concatenating to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam done
23/01/03 11:52:17 INFO IndexFileMerger: Merging .sbi files in temp directory ../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam.sbi
23/01/03 11:52:17 INFO IndexFileMerger: Done merging .sbi files
23/01/03 11:52:17 INFO IndexFileMerger: Merging .bai files in temp directory ../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam.parts/ to /Users/vtimonin/Desktop/Work/test/workflow/../interim/CPCT12345679R_HJJLGCCXX_S1_L001.dedup.bam.bai
23/01/03 11:52:17 INFO IndexFileMerger: Done merging .bai files
23/01/03 11:52:17 INFO SparkUI: Stopped Spark web UI at http://tsf-492-wpa-2-052.epfl.ch:4040
23/01/03 11:52:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/03 11:52:18 INFO MemoryStore: MemoryStore cleared
23/01/03 11:52:18 INFO BlockManager: BlockManager stopped
23/01/03 11:52:18 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/03 11:52:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/03 11:52:18 INFO SparkContext: Successfully stopped SparkContext
11:52:18.103 INFO  MarkDuplicatesSpark - Shutting down engine
[January 3, 2023 11:52:18 AM CET] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.28 minutes.
Runtime.totalMemory()=423100416
23/01/03 11:52:18 INFO ShutdownHookManager: Shutdown hook called
23/01/03 11:52:18 INFO ShutdownHookManager: Deleting directory /private/var/folders/6q/pgqvpyvd44b65lht2ypblldr0000gq/T/tmppyk8zsur/spark-22bbfc62-d425-4d9f-8a9b-855af6b99990
